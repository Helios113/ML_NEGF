{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "from data_loader import NEFG3x3Set\n",
    "from AE import AE\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#Verify that the files are correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the MNIST Dataset\n",
    "dataset = NEFG3x3Set(\"info_dat_pot_std.csv\",\n",
    "                     \"data/3x12x16\", \"dat_pot_std\", transform=True, device=\"cpu\")\n",
    "model = AE()\n",
    "model.load_state_dict(torch.load(\"trained_models/3x12_16_pot_loss.mp\"))\n",
    "loss_function = torch.nn.L1Loss()\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_loss = []\n",
    "inp_loss = []\n",
    "\n",
    "rloss = 0\n",
    "iloss = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1600\n",
    "# 1500 - example of very small data\n",
    "# 1000 - very small nums\n",
    "# 3000 - bigger numbers\n",
    "(inp, tar, _, _, _) = dataset[1600]\n",
    "# 4\n",
    "# Prediction Loss: tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
    "# Input Loss: tensor(0.0057)\n",
    "inp = inp.reshape(71*26).float()\n",
    "\n",
    "rec = model(inp).float().reshape(71, 26)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=3, figsize=(4, 12))\n",
    "pos = ax[0].imshow(rec.detach().numpy())\n",
    "c_bar = fig.colorbar(pos, ax=ax[0])\n",
    "# print(rec.min(), rec.max())\n",
    "# print(torch.sum(rec))\n",
    "\n",
    "\n",
    "tar = tar.reshape(71, 26).float()\n",
    "pos = ax[1].imshow(tar.detach().numpy())\n",
    "c_bar = fig.colorbar(pos, ax=ax[1])\n",
    "# print(torch.sum(tar))\n",
    "\n",
    "\n",
    "inp = inp.reshape(71, 26).float()\n",
    "pos = ax[2].imshow(inp.detach().numpy())\n",
    "c_bar = fig.colorbar(pos, ax=ax[2])\n",
    "# print(inp.min(), inp.max())\n",
    "# print(torch.sum(inp))\n",
    "plt.show()\n",
    "print(\"Prediction Loss:\", loss_function(tar, rec))\n",
    "\n",
    "print(\"Input Loss:\", loss_function(tar, inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AE(\n",
       "  (encoder): Sequential(\n",
       "    (0): Linear(in_features=1846, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=265, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=265, out_features=128, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=128, out_features=64, bias=True)\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=64, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=256, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=256, out_features=512, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=512, out_features=1846, bias=True)\n",
       "  )\n",
       "  (short_circuit): Sequential(\n",
       "    (0): Linear(in_features=1846, out_features=64, bias=True)\n",
       "    (1): Tanh()\n",
       "    (2): Linear(in_features=64, out_features=1846, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download the MNIST Dataset\n",
    "dataset = NEFG3x3Set(\"info_dat_charge_std.csv\",\n",
    "                     \"data/3x12x16\", \"dat_charge_std\", transform=True, device=\"cpu\")\n",
    "model = AE()\n",
    "model.load_state_dict(torch.load(\"trained_models/3x12_16_charge_loss.mp\"))\n",
    "loss_function = torch.nn.L1Loss()\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test_data = torch.utils.data.DataLoader(dataset=dataset, batch_size=32,\n",
    "# #                                             shuffle=True)\n",
    "# Prediction Loss: tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
    "# Input Loss: tensor(0.0094)\n",
    "for (inp, tar, name, ma, mn) in dataset:\n",
    "    inp = inp.reshape(-1, 71*26).float()\n",
    "    rec = model(inp).cpu().detach().numpy().reshape(71, 26)\n",
    "    rec = np.power(10,(rec*(ma-mn))+mn)\n",
    "    # rec = (rec*(max-min))+min    \n",
    "    np.savetxt(\"rec_data/3x12_16_charge/\"+name.replace(\"inp\", \"rec\"), rec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.log10(np.loadtxt(join(img_dir, f)))-j[1])/(j[0]-j[1])\n",
    "\n",
    "np.power(10,(n*(j[0]-j[1])+j[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_negf.venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ac4fa590126cfd0c907750eabeb448120b48d79d4b700ecf978f11f4f3eb84e8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

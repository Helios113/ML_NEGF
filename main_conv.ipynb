{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "from data_loader import NEFG3x3Set\n",
    "from FCNN import AE\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Download the MNIST Dataset\n",
    "dataset = NEFG3x3Set(\"info_dat_charge_std.csv\", \"data_3x3_12\", \"dat_charge_std\",transform=True)\n",
    "\n",
    "length = len(dataset)\n",
    "train_split = math.floor(length*.7)\n",
    "test_split = length - train_split\n",
    "\n",
    "train_inds, test_inds = torch.utils.data.random_split(dataset, [train_split, test_split], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "\n",
    "\n",
    "# Model Initialization\n",
    "model = AE()\n",
    "\n",
    "# Validation using MSE Loss function\n",
    "loss_function = torch.nn.L1Loss()\n",
    "\n",
    "# Using an Adam Optimizer with lr = 0.\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                             lr=1e-4)\n",
    "\n",
    "train_data = torch.utils.data.DataLoader(dataset=train_inds, batch_size=32,\n",
    "                                            shuffle=True)\n",
    "test_data = torch.utils.data.DataLoader(dataset=test_inds, batch_size=32,\n",
    "                                            shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inp, tar, _,_,_ = train_inds[12]\n",
    "# inp = inp.float()\n",
    "# print(inp.shape)\n",
    "# rec = model(inp)\n",
    "# print(rec.shape)\n",
    "# ns = np.sqrt(rec.reshape(1,-1).shape[1]).astype(int)\n",
    "# rec = rec.reshape((ns,ns))\n",
    "# fig, ax = plt.subplots(nrows=1, figsize=(4,4))\n",
    "# pos = ax.imshow(rec.detach().numpy())\n",
    "# c_bar = fig.colorbar(pos, ax=ax)\n",
    "# print(rec.min(), rec.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 / 20\n",
      "Average training loss: 0.04109552130103111\n",
      "Average test loss: 0.036476682871580124\n",
      "Epoch 1 / 20\n",
      "Average training loss: 0.0317150242626667\n",
      "Average test loss: 0.03115907311439514\n",
      "Epoch 2 / 20\n",
      "Average training loss: 0.02656545117497444\n",
      "Average test loss: 0.026866460219025612\n",
      "Epoch 3 / 20\n",
      "Average training loss: 0.025411229580640793\n",
      "Average test loss: 0.02731805294752121\n",
      "Epoch 4 / 20\n",
      "Average training loss: 0.025338871404528618\n",
      "Average test loss: 0.02668708749115467\n",
      "Epoch 5 / 20\n",
      "Average training loss: 0.025254447013139725\n",
      "Average test loss: 0.02703728713095188\n",
      "Epoch 6 / 20\n",
      "Average training loss: 0.025269726291298866\n",
      "Average test loss: 0.026639990508556366\n",
      "Epoch 7 / 20\n",
      "Average training loss: 0.02512899786233902\n",
      "Average test loss: 0.026422757655382156\n",
      "Epoch 8 / 20\n",
      "Average training loss: 0.02506629377603531\n",
      "Average test loss: 0.02729838155210018\n",
      "Epoch 9 / 20\n",
      "Average training loss: 0.025198962539434433\n",
      "Average test loss: 0.026442229747772217\n",
      "Epoch 10 / 20\n",
      "Average training loss: 0.025045324116945267\n",
      "Average test loss: 0.026390738785266876\n",
      "Epoch 11 / 20\n",
      "Average training loss: 0.02501155436038971\n",
      "Average test loss: 0.026393329724669456\n",
      "Epoch 12 / 20\n",
      "Average training loss: 0.025078479200601578\n",
      "Average test loss: 0.026456043124198914\n",
      "Epoch 13 / 20\n",
      "Average training loss: 0.025012440979480743\n",
      "Average test loss: 0.026423543691635132\n",
      "Epoch 14 / 20\n",
      "Average training loss: 0.0250918660312891\n",
      "Average test loss: 0.026445459574460983\n",
      "Epoch 15 / 20\n",
      "Average training loss: 0.024967938661575317\n",
      "Average test loss: 0.026485228911042213\n",
      "Epoch 16 / 20\n",
      "Average training loss: 0.025071686133742332\n",
      "Average test loss: 0.02631574124097824\n",
      "Epoch 17 / 20\n",
      "Average training loss: 0.025017164647579193\n",
      "Average test loss: 0.026302406564354897\n",
      "Epoch 18 / 20\n",
      "Average training loss: 0.025043265894055367\n",
      "Average test loss: 0.026436198502779007\n",
      "Epoch 19 / 20\n",
      "Average training loss: 0.02502255327999592\n",
      "Average test loss: 0.026364509016275406\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "outputs = []\n",
    "losses = []\n",
    "local_loss  = 0\n",
    "txt1 = \"Epoch {epoch} / \"+str(epochs)\n",
    "txt2 = \"Average training loss: {loss}\"\n",
    "txt3 = \"Average test loss: {loss}\"\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(txt1.format(epoch = epoch))\n",
    "    for (inp, tar, _,_,_) in train_data:\n",
    "        model.train()\n",
    "        inp = inp.float()\n",
    "        tar = tar.float()\n",
    "\n",
    "        # Output of Autoencoder\n",
    "        reconstructed, _  = model(inp)\n",
    "\n",
    "        # Calculating the loss function\n",
    "        loss = loss_function(reconstructed, tar)\n",
    "        \n",
    "        local_loss=local_loss+loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    \n",
    "    print(txt2.format(loss = local_loss/len(train_data)))\n",
    "    losses.append(local_loss/len(test_data))\n",
    "    local_loss = 0\n",
    "    \n",
    "    for (inp, tar, _,_,_) in test_data:\n",
    "        model.eval()\n",
    "        \n",
    "        inp = inp.float()\n",
    "        tar = tar.float()\n",
    "        # Output of Autoencoder\n",
    "        reconstructed, _ = model(inp)\n",
    "\n",
    "        # Calculating the loss function\n",
    "        loss = loss_function(reconstructed, tar)\n",
    "        local_loss+=loss\n",
    "\n",
    "    \n",
    "    print(txt3.format(loss = local_loss/len(test_data)))\n",
    "    \n",
    "    local_loss = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the Plot Style\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    " \n",
    "# Plotting the last 100 values\n",
    "a = [i.detach().numpy() for i in losses]\n",
    "\n",
    "plt.plot(a)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1600\n",
    "# 1500 - example of very small data\n",
    "# 1000 - very small nums\n",
    "# 3000 - bigger numbers\n",
    "(inp, tar, _,_,_)  = dataset[1500]\n",
    "inp = inp.float()\n",
    "\n",
    "rec, _ = model(inp)\n",
    "rec = rec.reshape((-1,26)).float()\n",
    "fig, ax = plt.subplots(nrows=3, figsize=(4,12))\n",
    "pos = ax[0].imshow(rec.detach().numpy())\n",
    "c_bar = fig.colorbar(pos, ax=ax[0])\n",
    "print(rec.min(), rec.max())\n",
    "\n",
    "tar = tar.reshape((-1,26)).float()\n",
    "pos = ax[1].imshow(tar.detach().numpy())\n",
    "c_bar = fig.colorbar(pos, ax=ax[1])\n",
    "print(tar.min(), tar.max())\n",
    "\n",
    "inp = inp.reshape((-1,26)).float()\n",
    "pos = ax[2].imshow(inp.detach().numpy())\n",
    "c_bar = fig.colorbar(pos, ax=ax[2])\n",
    "print(inp.min(), inp.max())\n",
    "\n",
    "plt.show()\n",
    "print(\"Prediction Loss:\", loss_function(tar, rec))\n",
    "\n",
    "print(\"Input Loss:\", loss_function(tar, inp))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# dif = rec-tar\n",
    "# pos = ax.imshow(dif.detach().numpy())\n",
    "# c_bar = fig.colorbar(pos, ax=ax)\n",
    "# plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_NEGF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "278755bacb11a2bb6c74d61b6eea8fba4f0209dc1c6fbb66b86178b4c9b30e56"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

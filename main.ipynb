{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import random\n",
    "from data_loader import NEFGSet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Determine if any GPUs are available\n",
    "\"\"\"\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\" # NVIDIA GPU\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\" # Apple GPU\n",
    "else:\n",
    "    device = \"cpu\" # Defaults to CPU if NVIDIA GPU/Apple GPU aren't available\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "\n",
    "dataset = NEFGSet(\"info_dat_std_NEGFXY.csv\",\n",
    "                     \"data/3x12_16_damp00\", \"dat_std\")\n",
    "\n",
    "length = len(dataset)\n",
    "train_split = math.floor(length*.7)\n",
    "test_split = length - train_split\n",
    "batch_size = 50\n",
    "train_inds, test_inds = torch.utils.data.random_split(\n",
    "    dataset, [train_split, test_split], generator=torch.Generator().manual_seed(42))\n",
    "train_data = torch.utils.data.DataLoader(dataset=train_inds, batch_size=batch_size,\n",
    "                                         shuffle=True)\n",
    "test_data = torch.utils.data.DataLoader(dataset=test_inds, batch_size=batch_size,\n",
    "                                        shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A Convolutional Variational Autoencoder\n",
    "\"\"\"\n",
    "class VAE(nn.Module):\n",
    "    # ther og net had 128 final channels\n",
    "    def __init__(self, imgChannels=3, layers = [16,32,64,64]):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        modules = []\n",
    "        inChannels = imgChannels\n",
    "        outChannels = layers[0]\n",
    "        for i in layers:\n",
    "            modules.append(\n",
    "                nn.Sequential(\n",
    "                nn.Conv2d(in_channels=inChannels, out_channels=i, kernel_size=5),\n",
    "                nn.BatchNorm2d(i),\n",
    "                nn.Dropout(0.3),\n",
    "                nn.LeakyReLU()\n",
    "                )\n",
    "            )\n",
    "            inChannels = i\n",
    "\n",
    "        self.encoder = nn.Sequential(*modules)\n",
    "\n",
    "        self.mu = nn.Conv2d(inChannels,inChannels, 1)\n",
    "        self.logVar = nn.Conv2d(inChannels,inChannels, 1)\n",
    "        self.short = nn.Conv2d(imgChannels, 1, 1)\n",
    "\n",
    "        modules = []\n",
    "        layers.reverse()\n",
    "        for i in range(len(layers)-1):\n",
    "            inChannels = layers[i]\n",
    "            outChannels = layers[i+1]\n",
    "            modules.append(\n",
    "                nn.Sequential(\n",
    "                nn.ConvTranspose2d(in_channels=inChannels, out_channels=outChannels, kernel_size=5),\n",
    "                nn.BatchNorm2d(outChannels),\n",
    "                nn.Dropout(0.3),\n",
    "                nn.ReLU()\n",
    "                )\n",
    "            )\n",
    "        modules.append(\n",
    "                nn.Sequential(\n",
    "                nn.ConvTranspose2d(in_channels=layers[-1], out_channels=1, kernel_size=5),\n",
    "                )\n",
    "            )\n",
    "        self.decoder = nn.Sequential(*modules)\n",
    "\n",
    "    def encode(self, x):\n",
    "        x = self.encoder(x)\n",
    "        mu = self.mu(x)\n",
    "        logVar = self.logVar(x)\n",
    "        return mu,logVar\n",
    "\n",
    "    def decode(self, z):\n",
    "        return self.decoder(z)\n",
    "    \n",
    "    def reparamaterize(self, mu, logVar):\n",
    "        std = torch.exp(0.5 * logVar)\n",
    "        eps = Variable(torch.randn_like(std))\n",
    "        return eps * std + mu\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # mu,logVar = self.encode(x)\n",
    "        # z = self.reparamaterize(mu,logVar)\n",
    "        # out = torch.add(self.decode(z),x[:,0,...].unsqueeze(1))\n",
    "        # out = torch.add(self.decode(self.encoder(x)),self.short(x))\n",
    "        # out = self.decode(self.encoder(x))\n",
    "        out = torch.add(self.decode(self.encoder(x)),x[:,0,...].unsqueeze(1))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m kl_divergence1 \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     12\u001b[0m net\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m---> 13\u001b[0m \u001b[39mfor\u001b[39;00m idx, data \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_data, \u001b[39m0\u001b[39m):\n\u001b[1;32m     14\u001b[0m     out \u001b[39m=\u001b[39m net(data[\u001b[39m0\u001b[39m])\n\u001b[1;32m     16\u001b[0m     \u001b[39m# kl_divergence = batch_size *0.5* torch.mean(-1 - logVar + mu.pow(2) + logVar.exp())\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/torch-gpu/lib/python3.11/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    629\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/torch-gpu/lib/python3.11/site-packages/torch/utils/data/dataloader.py:672\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    671\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 672\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    673\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    674\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/torch-gpu/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;49;00m idx \u001b[39min\u001b[39;49;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/torch-gpu/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/torch-gpu/lib/python3.11/site-packages/torch/utils/data/dataset.py:297\u001b[0m, in \u001b[0;36mSubset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(idx, \u001b[39mlist\u001b[39m):\n\u001b[1;32m    296\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindices[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m idx]]\n\u001b[0;32m--> 297\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindices[idx]]\n",
      "File \u001b[0;32m~/Projects/ML_NEGF/data_loader.py:46\u001b[0m, in \u001b[0;36mNEFG3x3Set.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[39m# self.labels.iloc[idx, 2] =  self.labels.iloc[idx, 2][:-5]+\"3.txt\"\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[39m# self.labels.iloc[idx, 3] =  self.labels.iloc[idx, 2][:-5]+\"3.txt\"\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \n\u001b[1;32m     44\u001b[0m \u001b[39m# print(self.labels.iloc[idx, 2])\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m4\u001b[39m):\n\u001b[0;32m---> 46\u001b[0m     dat\u001b[39m.\u001b[39mappend(torch\u001b[39m.\u001b[39mfrom_numpy(np\u001b[39m.\u001b[39;49mloadtxt(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata_dir,\u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlabels\u001b[39m.\u001b[39;49miloc[idx, i\u001b[39m+\u001b[39;49m\u001b[39m2\u001b[39;49m])), dtype\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mfloat32\u001b[39;49m\u001b[39m\"\u001b[39;49m))\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice))\n\u001b[1;32m     48\u001b[0m \u001b[39mreturn\u001b[39;00m dat\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/torch-gpu/lib/python3.11/site-packages/numpy/lib/npyio.py:1338\u001b[0m, in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows, quotechar, like)\u001b[0m\n\u001b[1;32m   1335\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(delimiter, \u001b[39mbytes\u001b[39m):\n\u001b[1;32m   1336\u001b[0m     delimiter \u001b[39m=\u001b[39m delimiter\u001b[39m.\u001b[39mdecode(\u001b[39m'\u001b[39m\u001b[39mlatin1\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m-> 1338\u001b[0m arr \u001b[39m=\u001b[39m _read(fname, dtype\u001b[39m=\u001b[39;49mdtype, comment\u001b[39m=\u001b[39;49mcomment, delimiter\u001b[39m=\u001b[39;49mdelimiter,\n\u001b[1;32m   1339\u001b[0m             converters\u001b[39m=\u001b[39;49mconverters, skiplines\u001b[39m=\u001b[39;49mskiprows, usecols\u001b[39m=\u001b[39;49musecols,\n\u001b[1;32m   1340\u001b[0m             unpack\u001b[39m=\u001b[39;49munpack, ndmin\u001b[39m=\u001b[39;49mndmin, encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[1;32m   1341\u001b[0m             max_rows\u001b[39m=\u001b[39;49mmax_rows, quote\u001b[39m=\u001b[39;49mquotechar)\n\u001b[1;32m   1343\u001b[0m \u001b[39mreturn\u001b[39;00m arr\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/torch-gpu/lib/python3.11/site-packages/numpy/lib/npyio.py:999\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(fname, delimiter, comment, quote, imaginary_unit, usecols, skiplines, max_rows, converters, ndmin, unpack, dtype, encoding)\u001b[0m\n\u001b[1;32m    996\u001b[0m     data \u001b[39m=\u001b[39m _preprocess_comments(data, comments, encoding)\n\u001b[1;32m    998\u001b[0m \u001b[39mif\u001b[39;00m read_dtype_via_object_chunks \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 999\u001b[0m     arr \u001b[39m=\u001b[39m _load_from_filelike(\n\u001b[1;32m   1000\u001b[0m         data, delimiter\u001b[39m=\u001b[39mdelimiter, comment\u001b[39m=\u001b[39mcomment, quote\u001b[39m=\u001b[39mquote,\n\u001b[1;32m   1001\u001b[0m         imaginary_unit\u001b[39m=\u001b[39mimaginary_unit,\n\u001b[1;32m   1002\u001b[0m         usecols\u001b[39m=\u001b[39musecols, skiplines\u001b[39m=\u001b[39mskiplines, max_rows\u001b[39m=\u001b[39mmax_rows,\n\u001b[1;32m   1003\u001b[0m         converters\u001b[39m=\u001b[39mconverters, dtype\u001b[39m=\u001b[39mdtype,\n\u001b[1;32m   1004\u001b[0m         encoding\u001b[39m=\u001b[39mencoding, filelike\u001b[39m=\u001b[39mfilelike,\n\u001b[1;32m   1005\u001b[0m         byte_converters\u001b[39m=\u001b[39mbyte_converters)\n\u001b[1;32m   1007\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1008\u001b[0m     \u001b[39m# This branch reads the file into chunks of object arrays and then\u001b[39;00m\n\u001b[1;32m   1009\u001b[0m     \u001b[39m# casts them to the desired actual dtype.  This ensures correct\u001b[39;00m\n\u001b[1;32m   1010\u001b[0m     \u001b[39m# string-length and datetime-unit discovery (like `arr.astype()`).\u001b[39;00m\n\u001b[1;32m   1011\u001b[0m     \u001b[39m# Due to chunking, certain error reports are less clear, currently.\u001b[39;00m\n\u001b[1;32m   1012\u001b[0m     \u001b[39mif\u001b[39;00m filelike:\n",
      "File \u001b[0;32m<frozen codecs>:331\u001b[0m, in \u001b[0;36mgetstate\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "net = VAE(imgChannels=7).to(device)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=1e-3)\n",
    "num_epochs = 500\n",
    "loss = 0\n",
    "kl_divergence1 = 0\n",
    "min_loss = 1000\n",
    "l1=0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    loss1 = 0\n",
    "    kl_divergence1 = 0\n",
    "    net.train()\n",
    "    for idx, data in enumerate(train_data, 0):\n",
    "        out = net(data[0])\n",
    "        \n",
    "        # kl_divergence = batch_size *0.5* torch.mean(-1 - logVar + mu.pow(2) + logVar.exp())\n",
    "        loss = F.mse_loss(out, data[3].unsqueeze(1))# + kl_divergence\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss1 += loss.item()\n",
    "        # kl_divergence1+=kl_divergence\n",
    "    loss1 = loss1/len(test_data)\n",
    "    # kl_divergence1=kl_divergence1/len(test_data)\n",
    "    # print(kl_divergence1)\n",
    "    print('Epoch {}: Train Loss {}'.format(epoch,loss1))\n",
    "    l2=0\n",
    "    net.eval()\n",
    "    for data in test_data:\n",
    "        out = net(data[0])    \n",
    "        if epoch == 1:\n",
    "            cmp = data[1]\n",
    "            # print((data[3].shape))\n",
    "            l1+=F.mse_loss(data[3], cmp)\n",
    "        l2+=F.mse_loss(data[3].unsqueeze(1), out)\n",
    "    if l2<min_loss:\n",
    "        min_loss = l2\n",
    "        torch.save(net.state_dict(),\"trained_run2.sd\")\n",
    "    if epoch == 1:\n",
    "        print(\"CMP:\", l1)\n",
    "    print(\"out:\", l2)\n",
    "\n",
    "# Epoch 15: Train Loss 0.36227205101 kl-div 0-1\n",
    "# \n",
    "# Epoch 15: Train Loss 0.99161257338 kl-div std\n",
    "\n",
    "# Epoch 15: Train Loss 0.30827124285 kl-div std\n",
    "\n",
    "# Use 0-1 data - yes\n",
    "# Use whole range for layer 6 - X\n",
    "# Remove charge just use pot\n",
    "\n",
    "# Epoch 7: Train Loss 0.0947228386425055\n",
    "# Epoch 7: Train Loss 0.0694243241674625"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out: tensor(0.1363, device='mps:0')\n",
      "inp: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "l2=0\n",
    "l1=0\n",
    "l3=0\n",
    "\n",
    "fig, ax = plt.subplots(ncols=2)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_data:   \n",
    "        # print(len(data))      \n",
    "        cmp = data[0][:,0]\n",
    "        # a = ax[0].imshow(cmp.cpu(), cmap=\"inferno\")\n",
    "        # y = np.linspace(0,cmp.shape[0],7)[1:-1]\n",
    "        # x = np.linspace(0,cmp.shape[1],5)[1:-1]\n",
    "        # ax[0].hlines(y,0,cmp.shape[1]-1, colors='white')\n",
    "        # ax[0].vlines(x,0,cmp.shape[0]-1 ,colors='white')\n",
    "        # for i,x in enumerate(np.linspace(0,cmp.shape[1]-1, 9)[1::2]):\n",
    "        #     for y in np.linspace(0,cmp.shape[0]-1, 13)[1::2]:\n",
    "        #         ax[0].annotate(str(round(i/3,2)),[x,y],xytext=(-10, -3), textcoords='offset points', color='white', weight=\"bold\")\n",
    "                \n",
    "        # ax[0].axis('off')\n",
    "        # fig.colorbar(a, ax=ax[0],shrink=0.8)\n",
    "        cmp1 = data[3]\n",
    "        # b = ax[1].imshow(cmp.cpu())#, cmap=\"inferno\")\n",
    "        # y = np.linspace(0,cmp.shape[0],7)[1:-1]\n",
    "        # x = np.linspace(0,cmp.shape[1],5)[1:-1]\n",
    "        # ax[1].hlines(y,0,cmp.shape[1]-1, colors='white')\n",
    "        # ax[1].vlines(x,0,cmp.shape[0]-1 ,colors='white')\n",
    "        # for x in np.linspace(0,cmp.shape[1]-1, 9)[1::2]:\n",
    "        #     for i,y in enumerate(np.linspace(0,cmp.shape[0]-1, 13)[1::2]):\n",
    "        #         ax[1].annotate(str(round(i/5,2)),[x,y],xytext=(-7, -3), textcoords='offset points', color='white', weight=\"bold\")\n",
    "                \n",
    "        # ax[1].axis('off')\n",
    "        # fig.colorbar(b, ax=ax[1],shrink=0.8)\n",
    "        \n",
    "        \n",
    "        # plt.savefig(\"potc.pdf\",  format=\"pdf\",bbox_inches=\"tight\", pad_inches=0)\n",
    "        # break\n",
    "        # # print((data[3].shape))\n",
    "        # l1+=F.mse_loss(data[3], cmp)\n",
    "        l2+=F.mse_loss(cmp, cmp1)\n",
    "        # plt.imshow(out[3].squeeze().cpu())\n",
    "        # plt.show()\n",
    "\n",
    "        # plt.imshow(data[3][3].cpu())\n",
    "        # plt.show()\n",
    "        # break\n",
    "        # l3+=F.l1_loss(data[3], data[0][0].unsqueeze(1))\n",
    "\n",
    "# print(\"CMP:\", l1)\n",
    "print(\"out:\", l2)\n",
    "print(\"inp:\", l3)\n",
    "\n",
    "# 0.0021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(min_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
